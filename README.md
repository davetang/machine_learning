Machine learning
================

_Machine Learning is the study of computer algorithms that improve automatically through experience. --Tom Mitchell_

# A brief history of machine learning

Adapted from the section 1.2 of the book "Deep Learning with R".

* Probabilistic modelling was one of the earliest forms of machine learning, where the principles of statistics were applied to data analysis
* The Naive Bayes algorithm is one of the best known methods for carrying out probabilistic modelling
* Logistic regression is an algorithm with roots that date back to the early 19th century
* The core ideas of neural networks were investigated back in the 1950s
* In the 1970s, the backpropagation algorithm was originally introduced
* Kernel methods, especially Support Vector Machines (SVMs), become popular in the 90s
* Decision trees [date back in the 1960s](http://washstat.org/presentations/20150604/loh_slides.pdf)
* The first algorithm for random decision trees was created in 1995 and an extension of the algorithm, called Random Forests, was created in 2001
* Gradient boosting is a machine-learning technique based on ensembling weak prediction models, generally decision trees, which originated in 1997
* In 2012, the SuperVision team led by Alex Krizhevsky and advised by Geoffrey Hinton was able to achieve a top-five accuracy of [83.6% on the ImageNet challenge](http://www.image-net.org/challenges/LSVRC/2012/results.html)

# Resources

A list of useful resources for learning about machine learning with an emphasis on biological applications.

## Courses

* [Machine Learning with R skill track](https://www.datacamp.com/tracks/machine-learning) on DataCamp

## Presentations

* [Some Things Every Biologist Should Know About Machine Learning](http://www.bioconductor.org/help/course-materials/2003/Milan/Lectures/MachineLearning.pdf) by Robert Gentleman

## Tutorials

* [How to Perform a Logistic Regression in R](http://datascienceplus.com/perform-logistic-regression-in-r/)
* [A gentle introduction to decision trees using R](https://eight2late.wordpress.com/2016/02/16/a-gentle-introduction-to-decision-trees-using-r/)
* [A gentle introduction to random forests using R](https://eight2late.wordpress.com/2016/09/20/a-gentle-introduction-to-random-forests-using-r/)
* [Random Forest Regression and Classification in R and Python](http://blog.yhat.com/posts/comparing-random-forests-in-python-and-r.html)
* [Fitting a Neural Network in R using the neuralnet package](http://datascienceplus.com/fitting-neural-network-in-r/)

## Online content

* [A Tour of The Top 10 Algorithms for Machine Learning Newbies](https://towardsdatascience.com/a-tour-of-the-top-10-algorithms-for-machine-learning-newbies-dde4edffae11)
* [Comparing supervised learning algorithms](http://www.dataschool.io/comparing-supervised-learning-algorithms/)
* [How to get better at data science](http://www.dataschool.io/how-to-get-better-at-data-science/)

## Papers

* [What is Bayesian statistics](http://dx.doi.org/10.1038/nbt0904-1177) by Sean Eddy
* [What is a support vector machine?](http://dx.doi.org/10.1038/nbt1206-1565) by William Noble
* [What is a hidden Markov model?](http://dx.doi.org/10.1038/nbt1004-1315) by Sean Eddy
* [What are artificial neural networks](http://dx.doi.org/10.1038/nbt1386) by Anders Krogh
* [Deep learning for computational biology](http://dx.doi.org/10.15252/msb.20156651) by Angermueller et al.
* [Machine learning applications in genetics and genomics](http://dx.doi.org/10.1038/nrg3920) by Maxwell Libbrecht and William Noble
* [Conditional variable importance for random forests](http://www.ncbi.nlm.nih.gov/pubmed/18620558)

## Books

* [An Introduction to Statistical Learning](http://www-bcf.usc.edu/~gareth/ISL/) by Gareth James, Daniela Witten, Trevor Hastie, and Robert Tibshirani
* [Introduction to Machine Learning](https://mitpress.mit.edu/books/introduction-machine-learning) by Ethem Alpaydin
* [Deep Learning with R](https://www.manning.com/books/deep-learning-with-r) by Fran√ßois Chollet with J. J. Allaire

## Datasets

* [Medical Data for Machine Learning](https://github.com/beamandrew/medical-data) by Andrew Beam
* [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets.html)
* [Kaggle Datasets](https://www.kaggle.com/datasets)
* [A collection of microarray data](https://github.com/ramhiser/datamicroarray) by John Ramey

## Others

* Tom Mitchell's [home page](http://www.cs.cmu.edu/~tom/)
* [My notes on Random Forests](https://github.com/davetang/learning_random_forest)
* [No Free Lunch Theorems](http://www.no-free-lunch.org/)

