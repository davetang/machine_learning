---
title: "Classification And REgression Training"
output: md_document
---

```{r setup, include=FALSE}
library(tidyverse)
theme_set(theme_bw())
knitr::opts_chunk$set(cache = FALSE)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.path = "img/")
```

## Introduction

The `caret` [package](https://topepo.github.io/caret/) (Classification And REgression Training) is a set of functions that attempt to streamline the process for creating predictive models. The package contains tools for, by is not limited to:

* data splitting
* pre-processing
* feature selection
* model tuning using resampling
* variable importance estimation

This README was generated by running from the root directory of this repository:

    script/rmd_to_md.sh template/template.Rmd

Install packages if missing and load.

```{r load_package, message=FALSE, warning=FALSE}
.libPaths('/packages')
my_packages <- c('gbm', 'mlbench', 'caret')

for (my_package in my_packages){
  if(!require(my_package, character.only = TRUE)){
    install.packages(my_package, '/packages')
  }
  library(my_package, character.only = TRUE)
}
```

## Breast cancer data

Using the [Breast Cancer Wisconsin (Diagnostic) Data Set](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)).

```{r prepare_data}
data <- read.table(
   "../data/breast_cancer_data.csv",
   stringsAsFactors = FALSE,
   sep = ',',
   header = TRUE
)
data$class <- factor(data$class)
data <- data[,-1]

str(data)
```

## Pre-processing

### Zero- and near zero-variance predictors

Predictors that have zero- or near zero-variance are not useful for making predictions since different classes will have the same values.

```{r nzv}
data(mdrr)

nzv <- nearZeroVar(mdrrDescr, saveMetrics = TRUE)
nzv[nzv$nzv, ][1:6, ]
```

Remove zero- and near zero-variance predictors.

```{r remove_nzv}
nzv <- nearZeroVar(mdrrDescr)
filtered_descr <- mdrrDescr[, -nzv]
dim(filtered_descr)
```

### Correlated predictors

The `findCorrelation` function flags correlated predictors for removal.

```{r descr_cor}
descr_cor <- cor(filtered_descr)
summary(descr_cor[lower.tri(descr_cor)])
```

Remove highly correlated predictors.

```{r remove_cor}
highly_cor_descr <- findCorrelation(descr_cor, cutoff = 0.75)
filtered_descr <- filtered_descr[, -highly_cor_descr]

descr_cor_post <- cor(filtered_descr)
summary(descr_cor_post[lower.tri(descr_cor_post)])
```

Data dimension after removing correlated predictors.

```{r filtered_descr_no_cor}
dim(filtered_descr)
```

### Linear dependencies

Linear dependencies can occur when large numbers of binary chemical fingerprints are used to describe the structure of a molecule. The function `findLinearCombos` uses the QR decomposition of a matrix to enumerate sets of linear combinations.

```{r ltfr_design}
ltfr_design <- matrix(0, nrow=6, ncol=6)
ltfr_design[,1] <- c(1, 1, 1, 1, 1, 1)
ltfr_design[,2] <- c(1, 1, 1, 0, 0, 0)
ltfr_design[,3] <- c(0, 0, 0, 1, 1, 1)
ltfr_design[,4] <- c(1, 0, 0, 1, 0, 0)
ltfr_design[,5] <- c(0, 1, 0, 0, 1, 0)
ltfr_design[,6] <- c(0, 0, 1, 0, 0, 1)

colnames(ltfr_design) <- paste0("c", 1:6)
rownames(ltfr_design) <- paste0("r", 1:6)
ltfr_design
```

Note that columns two and three add up to the first column and columns four, five, and six also add up to the first column. `findLinearCombos` will return a list that enumerates these dependencies.

```{r combo_info}
combo_info <- findLinearCombos(ltfr_design)
combo_info
```

Remove linear dependencies.

```{r remove_linear}
ltfr_design[, -combo_info$remove]
```

### The `preProcess` function

The `preProcess` class can be used for many operations on predictors, including centering and scaling. The function estimates the required parameters for each operation and `predict.preProcess` is used to apply them to specific data sets.

#### Centring and scaling

The function `preProcess` does not pre-process the data but `predict.preProcess` is used for pre-processing.

```{r centre_and_scale}
set.seed(1984)
train_idx <- sample(seq(along = mdrrClass), length(mdrrClass)/2)

training <- filtered_descr[train_idx, ]
training_class <- mdrrClass[train_idx]
test <- filtered_descr[-train_idx, ]
test_class <- mdrrClass[-train_idx]

pre_proc_values <- preProcess(training, method = c("center", "scale"))

training_pre_proc <- predict(pre_proc_values, training)
test_pre_proc <- predict(pre_proc_values, test)
```

Before pre-processing.

```{r before_pre_process}
training[1:6, 1:6]
```

After pre-processing.

```{r after_pre_process}
training_pre_proc[1:6, 1:6]
```

#### Transforming predictors

Principal Component Analysis (PCA) can be used to transform data to a smaller sub-space where the new variables are uncorrelated with one another. The `preProcess` class can apply this transformation by including "pca" in the `method` argument (this will also force scaling of the predictors).

Independent Component Analysis (ICA) can also be used to find new variables that are linear combinations of the original set such that the components are independent.

The spatial sign transformation projects the data for a predictor to the unit circle in $p$ dimensions, where $p$ is the number of predictors. Essentially a vector of data is divided by its norm.

### Data splitting

Separate into training (80%) and testing (20%).

```{r split_data_manual}
set.seed(1984)
my_prob <- 0.8
my_split <- as.logical(
  rbinom(
    n = nrow(data),
    size = 1,
    p = my_prob
  )
)

train <- data[my_split,]
test <- data[!my_split,]

my_df <- rbind(
  prop.table(table(data$class)),
  prop.table(table(train$class)),
  prop.table(table(test$class))
)

rownames(my_df) <- c('orig', 'train', 'test')
my_df
```

The function `createDataPartition` can be used to create balanced splits of the data. If the `y` argument to this function is a factor, the random sampling occurs within each class and should preserve the overall class distribution of the data.

```{r create_data_part}
set.seed(1984)
train_idx <- createDataPartition(
  y = data$class,
  p = 0.8,
  list = FALSE,
  times = 1
)

train_caret <- data[train_idx, ]
test_caret <- data[-train_idx, ]

my_df <- rbind(
  prop.table(table(data$class)),
  prop.table(table(train_caret$class)),
  prop.table(table(test_caret$class))
)

rownames(my_df) <- c('orig', 'train', 'test')
my_df
```

## Model training and tuning

There are several functions that help to streamline the model building and evaluation process. The `train` function can be used to:

* estimate model performance from a training set
* evaluate, using resampling, the effect of model tuning parameters on performance
* choose the "optimal" model across these parameters

The first step in tuning the model is to choose a set of parameters to evaluate. Once the model and tuning parameter values have been defined, the type of resampling should be specified. _k_-fold cross-validation (once or repeated), leave-one-out cross-validation and bootstrap resampling methods can be used by `train`. After resampling, the process produces a profile of performance measures that is available for finding the tuning parameter values that should be used.

### An example

Using the `Sonar` data from the `mlbench` package.

```{r sonar_data}
data("Sonar")
str(Sonar[, 1:6])
```

Split.

```{r sonar_split}
set.seed(1984)
idx <- createDataPartition(Sonar$Class, p = 0.75, list = FALSE)
training <- Sonar[idx, ]
testing <- Sonar[-idx, ]
```

The function `trainControl` can be used to specify the type of resampling and in the example below we perform 10 by 10 cross-validation.

```{r sonar_train_control}
fit_control <- trainControl(
  method = "repeatedcv",
  number = 10,
  repeats = 10
)
```

The first two arguments to `train` are the predictor and outcome data objects, respectively. The third argument, `method`, specifies the type of model. In the example below, we fit a boosted tree model via the `gbm` package.

```{r sonar_boosted_tree}
set.seed(1984)
system.time(
  gbm_fit <- train(
    Class ~ .,
    data = training,
    method = "gbm",
    trControl = fit_control,
    verbose = FALSE
  )
)

gbm_fit
```

For a Gradient Boosting Machine (GBM) model, there are three main tuning parameters:

* complexity of the tree called `interaction.depth`
* number of iterations, i.e. trees (called `n.trees`)
* learning rate: how quickly the algorithm adapts, called `shrinkage`
* the minimum number of training set samples in a node to commence splitting (`n.minobsinnode`)

The default values tested for this model are shown in the first two columns; `shrinkage` and `n.minobsinnode` are not shown because the grid set of candidate models all use a single value for these tuning parameters.

The `Accuracy` column is the overall agreement rate averaged over cross-validation iterations. The agreement standard deviation is also calculated from the cross-validation results. The `Kappa` column is Cohen's (unweighted) Kappa statistic averaged across the resampling results.

`train` can also automatically create a grid of tuning parameters for some models. By default, if $p$ is the number of tuning parameters, the grid size is $3^p$.

The `train` function has an argument called `preProcess` that is used to specify what pre-processing should be carried out. This argument takes a character string of methods that would normally be passed to the `method` argument of the `preProcess` function.

The tuning parameter grid can be specified using the `tuneGrid` argument in the `train` function. Use `expand.grid` function to create a grid.

```{r gbm_grid}
gbm_grid <- expand.grid(
  interaction.depth = c(1, 5, 9),
  n.trees = (1:30)*50,
  shrinkage = 0.1,
  n.minobsinnode = 20
)

head(gbm_grid)
```

Train using parameters specified in our grid.

```{r train_with_grid}
set.seed(1984)
system.time(
  gbm_fit_grid <- train(
    Class ~ .,
    data = training,
    method = "gbm",
    trControl = fit_control,
    verbose = FALSE,
    tuneGrid = gbm_grid
  )
)

gbm_fit_grid
```

Plot grid results.

```{r line_plot_grid_res}
ggplot(gbm_fit_grid)
```

Heatmap.

```{r heatmap_grid_res}
trellis.par.set(caretTheme())
plot(gbm_fit_grid, plotType = "level")
```

Using area under the ROC curve as a performance metric.

```{r auroc}
fit_control_roc <- trainControl(
  method = "repeatedcv",
  number = 10,
  repeats = 10,
  classProbs = TRUE,
  summaryFunction = twoClassSummary
)

set.seed(1984)
system.time(
  gbm_fit_roc <- train(
    Class ~ .,
    data = training,
    method = "gbm",
    trControl = fit_control_roc,
    verbose = FALSE,
    tuneGrid = gbm_grid,
    metric = "ROC"
  )
)

gbm_fit_roc
```

Best model according to area under the ROC.

```{r slice_max}
slice_max(.data = gbm_fit_roc$results, order_by = ROC, n = 1)
```

The best parameters are stored in `bestTune`.

```{r best_tune}
gbm_fit_roc$bestTune
```

Density plot.

```{r roc_density}
trellis.par.set(caretTheme())
densityplot(gbm_fit_roc, pch = '|')
```

## Session info

Time built.

```{r time, echo=FALSE}
Sys.time()
```

Session info.

```{r session_info, echo=FALSE}
sessionInfo()
```

