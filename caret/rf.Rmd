---
title: "Random Forest tuning"
output: md_document
---

```{r setup, include=FALSE}
library(tidyverse)
theme_set(theme_bw())
knitr::opts_chunk$set(cache = FALSE)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.path = "img/")
```

## Introduction

This README was generated by running from the root directory of this repository:

    script/rmd_to_md.sh template/template.Rmd

Install packages if missing and load.

```{r load_package, message=FALSE, warning=FALSE}
.libPaths('/packages')
my_packages <- c('doParallel', 'e1071', 'randomForest', 'mlbench', 'caret')

for (my_package in my_packages){
  if(!require(my_package, character.only = TRUE)){
    install.packages(my_package, '/packages')
  }
  library(my_package, character.only = TRUE)
}
```

## Sonar data

From `?Sonar`

> This is the data set used by Gorman and Sejnowski in their study of the classification of sonar signals using a neural network. The task is to train a network to discriminate between sonar signals bounced off a metal cylinder and those bounced off a roughly cylindrical rock.
>
> Each pattern is a set of 60 numbers in the range 0.0 to 1.0. Each number represents the energy within a particular frequency band, integrated over a certain period of time. The integration aperture for higher frequencies occur later in time, since these frequencies are transmitted later during the chirp.
>
> The label associated with each record contains the letter "R" if the object is a rock and "M" if it is a mine (metal cylinder). The numbers in the labels are in increasing order of aspect angle, but they do not encode the angle directly.

```{r prepare_data}
data(Sonar, package = "mlbench")

my_feat <- Sonar[, -ncol(Sonar)]
my_lab <- Sonar[, ncol(Sonar)]

dim(my_feat)
```

## Pre-processing

### Zero- and near zero-variance predictors

Predictors that have zero- or near zero-variance are not useful for making predictions since different classes will have the same values.

```{r nzv}
nzv <- nearZeroVar(my_feat, saveMetrics = TRUE)
table(nzv$nzv)
```

### Correlated predictors

The `findCorrelation` function flags correlated predictors for removal.

```{r descr_cor}
my_cor <- cor(my_feat)
summary(my_cor[lower.tri(my_cor)])
```

Remove highly correlated predictors.

```{r remove_cor}
my_cor_feat <- findCorrelation(my_cor, cutoff = 0.90)

my_feat_filt <- my_feat[, -my_cor_feat]
my_cor <- cor(my_feat_filt)
summary(my_cor[lower.tri(my_cor)])
```

Data dimension after removing correlated predictors.

```{r filtered_descr_no_cor}
dim(my_feat_filt)
```

### Data splitting

Separate into training (80%) and testing (20%) using `createDataPartition`. If the `y` argument to this function is a factor, the random sampling occurs within each class and should preserve the overall class distribution of the data.

```{r create_data_part}
set.seed(1984)
my_idx <- createDataPartition(
  y = my_lab,
  p = 0.8,
  list = FALSE,
  times = 1
)

my_train <- my_feat_filt[my_idx, ]
my_train$class <- my_lab[my_idx]
my_test <- my_feat_filt[-my_idx, ]
my_test$class <- my_lab[-my_idx]
```

## Model training and tuning

The function `trainControl` can be used to specify the type of resampling and in the example below we perform 10 by 10 cross-validation. `classProbs` (logical) refers to whether class probabilities should be computed for classification models (along with predicted values) in each resample. `twoClassSummary` computes sensitivity, specificity and the area under the ROC curve.

```{r fit_control}
fit_control <- trainControl(
  method = "repeatedcv",
  number = 10,
  repeats = 10,
  classProbs = TRUE,
  summaryFunction = twoClassSummary
)
```

Try all possible `mtry` values.

```{r gbm_grid}
gbm_grid <- expand.grid(
  mtry = 1:ncol(my_train)
)
```

Train in parallel using half of all available CPUs.

```{r my_rf}
ncore <- ceiling(detectCores() / 2)

cl <- makePSOCKcluster(ncore)
registerDoParallel(cl)

set.seed(1984)
system.time(
  my_rf <- train(
    class ~ .,
    data = my_train,
    method = "rf",
    trControl = fit_control,
    tuneGrid = gbm_grid,
    metric = "ROC",
    verbose = FALSE
  )
)
stopCluster(cl)

my_rf$bestTune
```

Plot results.

```{r plot_my_rf}
ggplot(my_rf)
```

Best model according to area under the ROC.

```{r best_mtry}
slice_max(.data = my_rf$results, order_by = ROC, n = 1)
```

## Entire workflow

Implement the current workflow as a function to ease testing on a new data set (as long as the labels are stored in the last column).

```{r run_rf}
run_rf <- function(my_df, my_seed = 1984, max_mtry = 150, remove_nzv = TRUE, remove_cor = TRUE){
  my_feat <- my_df[, -ncol(my_df)]
  my_lab <- my_df[, ncol(my_df)]
  
  nzv <- nearZeroVar(my_feat)
  if(length(nzv) > 0 && remove_nzv){
    message(paste0("Removing ", length(nzv), " near zero variance features"))
    my_feat <- my_feat[, -nzv]
  }
  
  my_cor <- cor(my_feat)
  my_cor_feat <- findCorrelation(my_cor, cutoff = 0.90)
  if(length(my_cor_feat) > 0 && remove_cor){
    message(paste0("Removing ", length(my_cor_feat), " correlated features"))
    my_feat <- my_feat[, -my_cor_feat]
  }
  
  set.seed(my_seed)
  my_idx <- createDataPartition(
    y = my_lab,
    p = 0.8,
    list = FALSE,
    times = 1
  )
  my_train <- my_feat[my_idx, ]
  my_train$class <- my_lab[my_idx]
  my_test <- my_feat[-my_idx, ]
  my_test$class <- my_lab[-my_idx]
  
  fit_control <- trainControl(
    method = "repeatedcv",
    number = 10,
    repeats = 10,
    classProbs = TRUE,
    summaryFunction = twoClassSummary
  )
  
  if(ncol(my_train) < max_mtry){
    max_mtry <- ncol(my_train)
  }
  
  gbm_grid <- expand.grid(
    mtry = 1:max_mtry
  )
  
  ncore <- ceiling(detectCores() / 2)
  
  cl <- makePSOCKcluster(ncore)
  registerDoParallel(cl)
  
  set.seed(my_seed)
  system.time(
    my_rf <- train(
      class ~ .,
      data = my_train,
      method = "rf",
      trControl = fit_control,
      tuneGrid = gbm_grid,
      metric = "ROC",
      verbose = FALSE
    )
  )
  stopCluster(cl)
  
  return(my_rf)
}
```

Load spam data and run workflow.

```{r run_rf_on_spam}
spam_data <- read.csv(file = "../data/spambase.csv")
spam_data$class <- factor(ifelse(spam_data$class == 1, 'S', 'H'))
spam_rf <- run_rf(spam_data)
spam_rf$bestTune
```

Plot tuning results.

```{r spam_rf_tune}
ggplot(spam_rf)
```

## Session info

Time built.

```{r time, echo=FALSE}
Sys.time()
```

Session info.

```{r session_info, echo=FALSE}
sessionInfo()
```
